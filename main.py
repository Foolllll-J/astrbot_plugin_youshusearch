import asyncio
import aiohttp
import random
import re
import base64
from typing import Dict, List, Optional
from urllib.parse import urljoin, quote

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
import astrbot.api.message_components as Comp
from astrbot.api import logger

@register(
    "astrbot_plugin_youshusearch",  # æ’ä»¶ID
    "Foolllll",                    # ä½œè€…å
    "ä¼˜ä¹¦æœç´¢åŠ©æ‰‹",                  # æ’ä»¶æ˜¾ç¤ºåç§°
    "1.3",                         # ç‰ˆæœ¬å·
    "https://github.com/Foolllll-J/astrbot_plugin_youshusearch", # æ’ä»¶ä»“åº“åœ°å€
)
class YoushuSearchPlugin(Star):
    def __init__(self, context: Context, config=None):
        super().__init__(context)
        if config is None:
            config = {}
        self.search_api_endpoint = "api/novel/search"
        self.base_api_url = config.get("base_url", "https://www.ypshuo.com/")
        self.COOKIE_STRING = config.get("cookie", "")

        self.uaa_base_url = "https://www.uaa001.com"
        self.hs_headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        }
        
        logger.info(f"ä¼˜ä¹¦æœç´¢æ’ä»¶(ys)åˆå§‹åŒ–ï¼Œä½¿ç”¨çš„åŸºç¡€URL: {self.base_api_url}")
        if self.base_api_url == "https://www.ypshuo.com/":
            self.api = 1
            self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
        }
        else:
            self.api = 2
            self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0", 
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Cookie": self.COOKIE_STRING,
            "Referer": self.base_api_url
        }

        self.YS_PLATFORMS = {"ä»–ç«™", "æœ¬ç«™", "èµ·ç‚¹", "æ™‹æ±Ÿ", "ç•ªèŒ„", "åˆºçŒ¬çŒ«", "çºµæ¨ª", "é£å¢", "17K", "æœ‰æ¯’", "æ¯å£¤", "é“è¡€", "é€æµª", "æŒé˜…", "å¡”è¯»", "ç‹¬é˜…è¯»", "å°‘å¹´æ¢¦", "SF", "è±†ç“£", "çŸ¥ä¹", "å…¬ä¼—å·"}
        self.YS_CATEGORIES = {"ç„å¹»", "å¥‡å¹»", "æ­¦ä¾ ", "ä»™ä¾ ", "éƒ½å¸‚", "ç°å®", "å†›äº‹", "å†å²", "æ‚¬ç–‘", "æ¸¸æˆ", "ç«æŠ€", "ç§‘å¹»", "çµå¼‚", "äºŒæ¬¡å…ƒ", "åŒäºº", "å…¶ä»–", "ç©¿è¶Šæ—¶ç©º", "æ¶ç©ºå†å²", "æ€»è£è±ªé—¨", "éƒ½å¸‚è¨€æƒ…", "ä»™ä¾ å¥‡ç¼˜", "å¹»æƒ³è¨€æƒ…", "æ‚¬ç–‘æ¨ç†", "è€½ç¾çº¯çˆ±", "è¡ç”ŸåŒäºº", "è½»å°è¯´", "ç»¼åˆå…¶ä»–"}
        self.YS_STATUSES = {"è¿è½½ä¸­", "å·²å®Œç»“", "å·²å¤ªç›‘"}
        
    async def _perform_hs_search(self, session: aiohttp.ClientSession, keyword: str, page: int = 1) -> Optional[tuple[List[Dict], int]]:
        """
        é€šè¿‡APIæœç´¢hsç½‘ç«™ (uaa.com) çš„ä¹¦ç±ã€‚
        """
        search_api_url = urljoin(self.uaa_base_url, "/api/novel/app/novel/search")
        params = {
            "keyword": keyword,
            "page": page,
            "searchType": 1,
            "size": 20,
            "orderType": 0
        }
        try:
            async with session.get(search_api_url, params=params, headers=self.hs_headers, timeout=20) as response:
                response.raise_for_status()
                json_data = await response.json()

            if json_data.get("result") == "success" and "model" in json_data:
                model = json_data["model"]
                results = model.get("data", [])
                total_pages = model.get("totalPage", 1)
                logger.info(f"âœ… HS API æœç´¢ '{keyword}' (Page {page}) æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœï¼Œå…± {total_pages} é¡µã€‚")
                return results, total_pages
            else:
                logger.warning(f"âš ï¸ HS API æœç´¢ '{keyword}' è¿”å›å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {json_data.get('msg', 'æ— ä¿¡æ¯')}")
                return [], 0
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œ HS API æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return None

    async def _get_and_format_hs_details(self, event: AstrMessageEvent, session: aiohttp.ClientSession, novel_id: str):
        """
        è·å–ã€è§£æå¹¶æ ¼å¼åŒ– hs (uaa.com) çš„ä¹¦ç±è¯¦æƒ…ã€‚
        """
        novel_url = urljoin(self.uaa_base_url, f"/novel/intro?id={novel_id}")
        
        try:
            async with session.get(novel_url, headers=self.hs_headers, timeout=10) as response:
                response.raise_for_status()
                html_content = await response.text()

            novel_info = {}
            def clean_text(text):
                return text.strip() if text else 'æ— '

            title_match = re.search(r'<h1>(.*?)</h1>', html_content)
            novel_info['title'] = clean_text(title_match.group(1)) if title_match else 'æ— '
            
            author_match = re.search(r'ä½œè€…ï¼š\s*<a.*?>(.*?)</a>', html_content)
            novel_info['author'] = clean_text(author_match.group(1)) if author_match else 'æ— '

            status_match = re.search(r'<span class="update_state">çŠ¶æ€ï¼š(.*?)</span>', html_content)
            novel_info['status'] = clean_text(status_match.group(1)) if status_match else 'æ— '

            score_match = re.search(r'è¯„åˆ†ï¼š<span>(.*?)</span>', html_content)
            novel_info['score'] = clean_text(score_match.group(1)) if score_match else 'æ— '
            
            intro_match = re.search(r'<div class="txt ellipsis">å°è¯´ç®€ä»‹ï¼š(.*?)(?:</div>|<div class="arrow")', html_content, re.DOTALL)
            novel_info['intro'] = clean_text(intro_match.group(1)) if intro_match else 'æ— '
            
            tags = re.findall(r'<li><a href="/novel/list\?tag=.*?"><b>#</b>(.*?)</a></li>', html_content)
            novel_info['tags'] = tags if tags else []

            category_block_match = re.search(r'<div class="item">\s*é¢˜æï¼š\s*(.*?)</div>', html_content, re.DOTALL)
            if category_block_match:
                categories = re.findall(r'<a.*?>(.*?)</a>', category_block_match.group(1))
                novel_info['categories'] = [cat.strip() for cat in categories]
            else:
                novel_info['categories'] = []
            
            update_match = re.search(r'<div class="item">\s*æœ€æ–°ï¼š(.*?)\s*</div>', html_content)
            novel_info['latest_update'] = clean_text(update_match.group(1)) if update_match else 'æ— '

            reviews = []
            try:
                comments_url = urljoin(self.uaa_base_url, "/api/novel/app/novel/comments")
                params = {"novelId": novel_id, "sortType": 1, "page": 1, "rows": 5}
                async with session.get(comments_url, params=params, headers=self.hs_headers, timeout=10) as response:
                    response.raise_for_status()
                    comments_data = await response.json()
                    
                    if comments_data.get("result") == "success" and "data" in comments_data:
                        for item in comments_data["data"]:
                            score_data = item.get('score')
                            score_val = 'æ— '
                            if isinstance(score_data, dict):
                                score_val = score_data.get('source', 'æ— ')
                            elif isinstance(score_data, (int, float)):
                                score_val = f"{score_data:.1f}"

                            reviews.append({
                                'author': item.get('nickName', 'åŒ¿å'),
                                'content': item.get('content', ''),
                                'score': score_val,
                                'time': item.get('createTimeFormat', '')
                            })
                        logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(reviews)} æ¡ä¹¦è¯„ for ID {novel_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–ä¹¦è¯„å¤±è´¥ for ID {novel_id} (å¯èƒ½éœ€è¦ç™»å½•æˆ–æ¥å£å¤±æ•ˆ): {e}")
            
            message_text = f"---ã€{novel_info['title']}ã€‘---\n"
            message_text += f"ä½œè€…: {novel_info['author']}\n"
            message_text += f"è¯„åˆ†: {novel_info['score']}\n"
            message_text += f"çŠ¶æ€: {novel_info['status']}\n"
            
            if novel_info['categories']:
                message_text += f"é¢˜æ: {' '.join(novel_info['categories'])}\n"
            
            if novel_info['tags']:
                message_text += f"æ ‡ç­¾: {' '.join(novel_info['tags'])}\n"
            
            message_text += f"æ›´æ–°: {novel_info['latest_update']}\n"
            message_text += f"ç®€ä»‹: {novel_info['intro']}\n"

            if reviews:
                message_text += "\n--- ğŸ“ æœ€æ–°ä¹¦è¯„ ---\n"
                for r in reviews:
                    message_text += f"{r['author']} ({r['score']}åˆ†, {r['time']}): {r['content']}\n"
            
            yield event.plain_result(message_text)

        except Exception as e:
            logger.error(f"âŒ è·å–HSä¹¦ç±è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"ğŸ˜¢ è·å–ä¹¦ç± {novel_id} è¯¦æƒ…å¤±è´¥ã€‚")

    @filter.command("hs")
    async def hs_search_command(self, event: AstrMessageEvent):
        command_text = event.message_str.strip()
        command_parts = command_text.split()
        
        if not command_parts or command_parts[0].lower() != 'hs' or len(command_parts) < 2:
            yield event.plain_result("âŒ ç”¨æ³•: /hs <ä¹¦å> [åºå· | -é¡µç ]")
            return

        args = command_parts[1:]
        book_name, page_to_list, item_index = "", 1, None
        last_arg = args[-1] if args else ""
        if len(args) > 1 and last_arg.startswith('-') and last_arg[1:].isdigit():
            page_to_list = int(last_arg[1:])
            if page_to_list == 0: page_to_list = 1
            book_name = " ".join(args[:-1]).strip()
        elif len(args) > 1 and last_arg.isdigit():
            item_index = int(last_arg)
            if item_index == 0: item_index = None
            book_name = " ".join(args[:-1]).strip()
        else:
            book_name = " ".join(args).strip()
        if not book_name:
            yield event.plain_result("âŒ è¯·æä¾›æœ‰æ•ˆçš„ä¹¦åè¿›è¡Œæœç´¢ã€‚")
            return

        logger.info(f"ç”¨æˆ· {event.get_sender_id()} è§¦å‘ /hs, æœç´¢:'{book_name}', åºå·:{item_index}, åˆ—è¡¨é¡µ:{page_to_list}")

        try:
            async with aiohttp.ClientSession() as session:
                page_to_fetch = page_to_list
                search_info = await self._perform_hs_search(session, book_name, page=page_to_fetch)

                if search_info is None or not search_info[0]:
                    yield event.plain_result(f"ğŸ˜¢ æœªæ‰¾åˆ°å…³äºã€{book_name}ã€‘çš„ä»»ä½•ä¹¦ç±ä¿¡æ¯ã€‚")
                    return
                
                search_results, max_pages = search_info

                if page_to_fetch > max_pages and max_pages > 0:
                    yield event.plain_result(f"âŒ æ‚¨è¯·æ±‚çš„ç¬¬ {page_to_fetch} é¡µä¸å­˜åœ¨ï¼Œã€{book_name}ã€‘çš„æœç´¢ç»“æœæœ€å¤šåªæœ‰ {max_pages} é¡µã€‚")
                    return

                if item_index is None: # æ˜¾ç¤ºåˆ—è¡¨
                    results_per_page = 20
                    start_num = (page_to_fetch - 1) * results_per_page + 1
                    message_text = f"ä»¥ä¸‹æ˜¯ã€{book_name}ã€‘çš„ç¬¬ {page_to_fetch}/{max_pages} é¡µæœç´¢ç»“æœ:\n"
                    for i, book in enumerate(search_results):
                        num = start_num + i
                        title = book.get('title', 'æœªçŸ¥ä¹¦ç±')
                        authors = book.get('authors', 'æœªçŸ¥ä½œè€…')
                        
                        score_value = book.get('score')
                        if isinstance(score_value, (int, float)):
                            score = f"{score_value:.2f}"
                        else:
                            score = 'N/A'

                        message_text += f"{num}. {title}\n    ä½œè€…ï¼š{authors} | è¯„åˆ†: {score}\n"
                    
                    message_text += f"\nğŸ’¡ è¯·ä½¿ç”¨ `/hs {book_name} <åºå·>` æŸ¥çœ‹è¯¦æƒ…"
                    if page_to_fetch < max_pages:
                        message_text += f"ï¼Œæˆ– `/hs {book_name} -{page_to_fetch + 1}` ç¿»é¡µã€‚"
                    yield event.plain_result(message_text)
                else: # æ˜¾ç¤ºè¯¦æƒ…
                    results_per_page = 20
                    index_on_page = (item_index - 1) % results_per_page
                    correct_page = (item_index - 1) // results_per_page + 1

                    if correct_page != page_to_fetch:
                        yield event.plain_result(f"â³ åºå·ã€{item_index}ã€‘ä½äºç¬¬ {correct_page} é¡µï¼Œæ­£åœ¨ä¸ºæ‚¨è·³è½¬...")
                        page_to_fetch = correct_page
                        search_info = await self._perform_hs_search(session, book_name, page=page_to_fetch)
                        if search_info is None or not search_info[0]:
                            yield event.plain_result(f"ğŸ˜¢ æœªåœ¨ç¬¬ {correct_page} é¡µæ‰¾åˆ°å…³äºã€{book_name}ã€‘çš„ä¿¡æ¯ã€‚")
                            return
                        search_results, _ = search_info
                    
                    if not (0 <= index_on_page < len(search_results)):
                        yield event.plain_result(f"âŒ åºå·ã€{item_index}ã€‘åœ¨ç¬¬ {page_to_fetch} é¡µä¸Šä¸å­˜åœ¨ã€‚")
                        return

                    selected_book = search_results[index_on_page]
                    novel_id = selected_book.get('id')
                    if not novel_id:
                        yield event.plain_result(f"âŒ æ— æ³•è·å–åºå·ä¸ºã€{item_index}ã€‘çš„ä¹¦ç±IDã€‚")
                        return

                    async for result in self._get_and_format_hs_details(event, session, str(novel_id)):
                        yield result
        except Exception as e:
            logger.error(f"æœç´¢hsä¹¦ç± '{book_name}' å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ æœç´¢hsä¹¦ç±æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")

    async def _perform_search(self, session: aiohttp.ClientSession, keyword: str, page: int = 1) -> Optional[tuple[List[Dict], int]]:
        if self.api == 1:
            search_api_url = urljoin(self.base_api_url, self.search_api_endpoint)
            params = {"keyword": keyword, "page": str(page)}
            try:
                async with session.get(search_api_url, params=params, headers=self.headers, timeout=20) as response:
                    response.raise_for_status()
                    json_content = await response.json()
                    logger.info(f"æœç´¢ '{keyword}' (Page {page}) APIè°ƒç”¨æˆåŠŸã€‚")
                    if json_content.get("code") == "00" and "data" in json_content:
                        data = json_content["data"]
                        results = data.get("data", []) 
                        total_pages = int(data.get("pageAll", 1))
                        return results, total_pages
                    else:
                        return None
            except Exception as e:
                logger.error(f"âŒ æ‰§è¡ŒAPIæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                return None

        elif self.api == 2:
            try:
                results_per_page = 20
                encoded_keyword = quote(keyword)
                search_url = urljoin(self.base_api_url, f"/search/all/{encoded_keyword}/{page}.html")
                logger.info(f"æ­£åœ¨è®¿é—®æœç´¢URL: {search_url}")

                async with session.get(search_url, headers=self.headers, timeout=20) as response:
                    response.raise_for_status()
                    body = await response.read()
                    encoding = response.charset or 'utf-8'
                    html_content = body.decode(encoding, errors='replace') 
                
                def clean_html(raw_html):
                    return re.sub(r'<[^>]+>', '', raw_html).strip()

                if 'å…±æœ‰<b class="hot">' in html_content:
                    logger.info("æ£€æµ‹åˆ°æœç´¢ç»“æœåˆ—è¡¨é¡µï¼ŒæŒ‰åˆ—è¡¨è§£æã€‚")
                    total_results = 0
                    total_match = re.search(r'å…±æœ‰<b class="hot">\s*(\d+)\s*</b>æ¡ç»“æœ', html_content)
                    if total_match:
                        total_results = int(total_match.group(1))
                    
                    total_pages = (total_results + results_per_page - 1) // results_per_page if total_results > 0 else 1
                    
                    results = []
                    result_blocks = re.findall(r'<div class="c_row">.*?<div class="cb"></div>', html_content, re.DOTALL)
                    
                    for block in result_blocks:
                        book_info = {}
                        name_match = re.search(r'<span class="c_subject"><a href="/book/(\d+)">(.*?)</a></span>', block, re.DOTALL)
                        if name_match:
                            book_info['id'] = int(name_match.group(1))
                            book_info['novel_name'] = clean_html(name_match.group(2))
                        
                        author_match = re.search(r'<span class="c_label">ä½œè€…ï¼š</span><span class="c_value">(.*?)</span>', block, re.DOTALL)
                        if author_match:
                            book_info['author_name'] = clean_html(author_match.group(1))
                        
                        score_match = re.search(r'<span class="c_rr">([\d.]+)</span>', block)
                        if score_match:
                            book_info['score'] = score_match.group(1)
                        
                        scorer_match = re.search(r'<span class="stard">\((\d+)äººè¯„åˆ†\)</span>', block)
                        if scorer_match:
                            book_info['scorer'] = scorer_match.group(1)
                        
                        if 'id' in book_info and 'novel_name' in book_info:
                            results.append(book_info)
                    
                    logger.info(f"æˆåŠŸä»åˆ—è¡¨é¡µè§£æåˆ° {len(results)} æ¡ç»“æœï¼Œå…± {total_pages} é¡µã€‚")
                    return results, total_pages
                else:
                    logger.info("æœªæ‰¾åˆ°æœç´¢åˆ—è¡¨ï¼Œå°è¯•æŒ‰å•æœ¬ä¹¦ç±è¯¦æƒ…é¡µè§£æ...")
                    name_match = re.search(r'<title>(.*?)-.*?-ä¼˜ä¹¦ç½‘</title>', html_content)
                    id_match = re.search(r"uservote\.php\?id=(\d+)|rating\('\d+',\s*'(\d+)'\)|addbookcase\.php\?bid=(\d+)", html_content)

                    if name_match and id_match:
                        novel_id_str = next((gid for gid in id_match.groups() if gid is not None), None)
                        if novel_id_str:
                            novel_name = clean_html(name_match.group(1))
                            novel_id = int(novel_id_str)
                            logger.info(f"æœç´¢ç»“æœä¸ºç›´æ¥è·³è½¬ï¼Œè§£æåˆ°ä¹¦ç±: '{novel_name}' (ID: {novel_id})")
                            
                            results = [{'id': novel_id, 'novel_name': novel_name}]
                            total_pages = 1
                            return results, total_pages

                    logger.warning("é¡µé¢æ—¢ä¸æ˜¯æœç´¢åˆ—è¡¨ä¹Ÿä¸æ˜¯æœ‰æ•ˆçš„ä¹¦ç±è¯¦æƒ…é¡µï¼Œåˆ¤å®šä¸ºæ— ç»“æœã€‚")
                    return [], 0

            except Exception as e:
                logger.error(f"âŒ æ‰§è¡Œæœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                return None
        
    async def _get_latest_novel_id(self, session: aiohttp.ClientSession) -> Optional[int]:
        if self.api == 1:
            url = "https://www.ypshuo.com/"
            try:
                async with session.get(url, headers=self.headers, timeout=10) as response:
                    response.raise_for_status()
                    html_content = await response.text()
                    matches = re.findall(r'href="/novel/(\d+)\.html"', html_content)
                    if matches:
                        latest_id = max([int(id) for id in matches])
                        return latest_id
            except Exception:
                return None
        elif self.api == 2:
            url = "https://youshu.me/"
            try:
                async with session.get(url, headers=self.headers, timeout=10) as response:
                    response.raise_for_status()
                    html_content = await response.text()
                    new_book_section_match = re.search(
                        r'<div class="blocktitle">æ–°ä¹¦è‡ªåŠ©æ¨è.*?</div>\s*<div class="blockcontent">.*?</ul>',
                        html_content, re.DOTALL)
                    if not new_book_section_match:
                        return None
                    new_book_block = new_book_section_match.group(0)
                    matches = re.findall(r'href="/book/(\d+)"', new_book_block)
                    if matches:
                        latest_id = max([int(id) for id in matches])
                        return latest_id
                    else:
                        return None
            except Exception:
                return None

    async def _get_novel_details_from_html(self, html_content: str, novel_id: str) -> Dict:
        def clean_html_content(text):
            if not text:
                return 'æ— '
            text = re.sub(r'<[^>]+>', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            text = re.sub(r'\.{3,}å…¨æ–‡$', '...', text).strip()
            return text if text else 'æ— '
        
        novel_info = {}
        
        if self.api == 1:
            try:
                og_image_match = re.search(r'<meta[^>]*?name="og:image"[^>]*?content="(.*?)"', html_content)
                if og_image_match:
                    image_url = og_image_match.group(1)
                    if image_url.startswith('//'):
                        image_url = 'https:' + image_url
                    elif image_url.startswith('/'):
                        image_url = urljoin(self.base_api_url, image_url)
                    novel_info['image_url'] = image_url
                else:
                    image_match = re.search(r'<img src="(.*?)"[^>]*?class="book-img"', html_content)
                    if image_match:
                        image_url = image_match.group(1)
                        if image_url.startswith('/'):
                            image_url = urljoin(self.base_api_url, image_url)
                        novel_info['image_url'] = image_url
                    else:
                        novel_info['image_url'] = None
                name_match = re.search(r'<h1 class="book-name".*?>(.*?)</h1>', html_content, re.DOTALL)
                novel_info['novel_name'] = name_match.group(1).strip() if name_match else 'æ— '
                author_match = re.search(r'ä½œè€…ï¼š<span class="text-red-500".*?>(.*?)</span>', html_content)
                novel_info['author_name'] = author_match.group(1).strip() if author_match else 'æ— '
                novel_info['tags'] = []
                tag_block_match = re.search(r'<div class="tag-list"[^>]*?>(.*?)</div>', html_content, re.DOTALL)
                if tag_block_match:
                    tag_html = tag_block_match.group(1)
                    tags_list = re.findall(r'<span[^>]*?>(.*?)</span>', tag_html)
                    if tags_list:
                        novel_info['tags'] = [tag.strip() for tag in tags_list if tag.strip()]
                word_count_match = re.search(r'å­—æ•°ï¼š(.*?)ä¸‡å­—', html_content)
                if word_count_match:
                    try:
                        word_str = word_count_match.group(1).strip().replace(',', '')
                        novel_info['word_number'] = float(word_str) * 10000
                    except (ValueError, TypeError):
                        novel_info['word_number'] = None
                else:
                    novel_info['word_number'] = None
                score_data_matches = re.findall(r'<div class="item"[^>]*?>\s*<p class="score"[^>]*?>\s*(.*?)\s*</p>\s*<p[^>]*?>(.*?)</p>\s*</div>', html_content, re.DOTALL)
                novel_info['score'] = 'æ— '
                novel_info['scorer'] = 'æ— '
                for value, label in score_data_matches:
                    if label.strip() == 'è¯„åˆ†':
                        novel_info['score'] = value.strip()
                    elif label.strip() == 'è¯„åˆ†äººæ•°':
                        novel_info['scorer'] = value.strip()
                status_match = re.search(r'çŠ¶æ€ï¼š\s*(.*?)\s*<', html_content)
                novel_info['status'] = status_match.group(1).strip() if status_match else 'æ— '
                update_time_match = re.search(r'æ›´æ–°æ—¶é—´ï¼š\s*(.*?)\s*</div>', html_content)
                novel_info['update_time_str'] = update_time_match.group(1).strip() if update_time_match else 'æ— '
                reviews = []
                review_item_regex = re.compile(
                    r'<div class="author-info"[^>]*?>(.*?)</div>'r'.*?'r'aria-valuenow="([^"]+)"'r'.*?'r'<span class="content-inner-details"[^>]*?>(.*?)</span>', re.DOTALL)
                all_reviews = review_item_regex.findall(html_content)
                for author, rating, content_block in all_reviews[:3]: 
                    content = re.sub(r'<[^>]+>', '', content_block)
                    content = re.sub(r'[\r\n\t]+', '', content).strip()
                    content = re.sub(r'\.{3,}å…¨æ–‡$', '...', content).strip()
                    if content:
                        reviews.append({'author': author.strip(), 'content': content, 'rating': rating})
                novel_info['reviews'] = reviews
                synopsis_match = re.search(r'<div style="white-space:pre-wrap;"[^>]*?>(.*?)</div>', html_content, re.DOTALL)
                synopsis_content = synopsis_match.group(1).strip() if synopsis_match else 'æ— '
                novel_info['synopsis'] = synopsis_content
                link_match = re.search(r'<a href="(http.*?)".*?rel="nofollow".*?>', html_content)
                novel_info['link'] = link_match.group(1).strip() if link_match else 'æ— '
                return novel_info
            except Exception as e:
                logger.error(f"âŒ DOMè§£æå¤±è´¥ã€‚é”™è¯¯: {e}")
                return {}

        elif self.api == 2:
            try:
                name_match = re.search(r'<title>(.*?)-.*?-ä¼˜ä¹¦ç½‘</title>', html_content)
                novel_info['novel_name'] = clean_html_content(name_match.group(1)) if name_match else 'æ— '
                author_match = re.search(r'ä½œè€…ï¼š<a.*?>(.*?)</a>', html_content)
                novel_info['author_name'] = clean_html_content(author_match.group(1)) if author_match else 'æ— '
                score_match = re.search(r'<span class="ratenum">(.*?)</span>', html_content)
                scorer_match = re.search(r'\((.*?)äººå·²è¯„\)', html_content)
                novel_info['score'] = clean_html_content(score_match.group(1)) if score_match else 'æ— '
                novel_info['scorer'] = clean_html_content(scorer_match.group(1)) if scorer_match else 'æ— '
                update_time_match = re.search(r'æœ€åæ›´æ–°ï¼š(.*?)</td>', html_content)
                novel_info['update_time_str'] = clean_html_content(update_time_match.group(1)) if update_time_match else 'æ— '
                synopsis_match = re.search(r'<div class="tabvalue"[^>]*?>\s*<div[^>]*?>(.*?)</div>', html_content, re.DOTALL)
                novel_info['synopsis'] = clean_html_content(synopsis_match.group(1)) if synopsis_match else 'æ— '
                link_match = re.search(r'<a class="btnlink b_hot mbs" href="(.*?)"', html_content)
                novel_info['link'] = clean_html_content(link_match.group(1)) if link_match else 'æ— '
                img_match = re.search(r'<a[^>]*?class="book-detail-img"[^>]*?><img src="(.*?)"', html_content)
                novel_info['image_url'] = urljoin(self.base_api_url, img_match.group(1).strip()) if img_match and img_match.group(1).strip() else None
                novel_info.update({'platform': 'æ— ', 'category': 'æ— ', 'status': 'æ— ', 'word_number': None})
                info_exp_match = re.search(r'<div class="author-item-exp">(.*?)</div>', html_content, re.DOTALL)
                if info_exp_match:
                    raw_text = info_exp_match.group(1).replace('<i class="author-item-line"></i>', '|')
                    clean_text = re.sub(r'<[^>]+>', '', raw_text)
                    info_parts = [part.strip() for part in clean_text.split('|') if part.strip()]
                    for part in info_parts:
                        if part in self.YS_PLATFORMS:
                            novel_info['platform'] = part
                        elif part in self.YS_CATEGORIES:
                            novel_info['category'] = part
                        elif part in self.YS_STATUSES:
                            novel_info['status'] = part
                        elif 'å­—' in part:
                            word_match = re.search(r'(\d+)', part)
                            if word_match:
                                novel_info['word_number'] = float(word_match.group(1))
                novel_info['tags'] = []
                tag_section_match = re.search(r'<b>æ ‡ç­¾ï¼š</b>(.*?)</div>', html_content, re.DOTALL)
                if tag_section_match:
                    tag_block = tag_section_match.group(1)
                    tags = re.findall(r'<a[^>]*?>(.*?)</a>', tag_block)
                    if tags:
                        novel_info['tags'] = [clean_html_content(tag) for tag in tags]
                reviews = []
                review_blocks = re.findall(r'<div class="c_row cf">.*?<div class="c_tag">', html_content, re.DOTALL)
                for block in review_blocks[:5]:
                    author_match = re.search(r'<p>(.*?)</p></a>\s*<p><div class="user-level">', block, re.DOTALL)
                    rating_match = re.search(r'<span title="(\d+)\s*é¢—æ˜Ÿ"', block, re.DOTALL)
                    content_match = re.search(r'<div class="c_description">(.*?)</div>', block, re.DOTALL)
                    if author_match and rating_match and content_match:
                        author = clean_html_content(author_match.group(1))
                        rating = rating_match.group(1)
                        content = clean_html_content(content_match.group(1))
                        if content and content != 'æ— ':
                            reviews.append({'author': author, 'content': content, 'rating': rating})
                novel_info['reviews'] = reviews
                return novel_info
            except Exception as e:
                logger.error(f"âŒ DOMè§£æ (youshu.me) å¤±è´¥ã€‚é”™è¯¯: {e}")
                return {}
            
    async def _get_and_format_novel_details(self, event: AstrMessageEvent, session: aiohttp.ClientSession, novel_id: str):
        if self.api == 1:
            novel_url = f"https://www.ypshuo.com/novel/{novel_id}.html"
        else:
            novel_url = f"https://youshu.me/book/{novel_id}"
        try:
            async with session.get(novel_url, headers=self.headers, timeout=10) as response:
                response.raise_for_status()
                html_content = await response.text()
            novel_info = await self._get_novel_details_from_html(html_content, str(novel_id))
            if not (novel_info and novel_info.get('novel_name', 'æ— ') != 'æ— '):
                raise ValueError(f"æ— æ³•ä»é¡µé¢ {novel_id} æå–æœ‰æ•ˆä¿¡æ¯ã€‚")
            if novel_info and novel_info.get('novel_name', 'æ— ') != 'æ— ':
                message_text = f"---ã€{novel_info.get('novel_name', 'æ— ')}ã€‘---\n"
                message_text += f"ä½œè€…: {novel_info.get('author_name', 'æ— ')}\n"
                if self.api == 2:
                    message_text += f"å¹³å°: {novel_info.get('platform', 'æœªçŸ¥')}\n"
                    message_text += f"åˆ†ç±»: {novel_info.get('category', 'æœªçŸ¥')}\n"
                tags = novel_info.get('tags')
                if tags:
                    message_text += f"æ ‡ç­¾: {' '.join(tags)}\n"
                word_number = novel_info.get('word_number')
                if word_number is not None and isinstance(word_number, (int, float)):
                    message_text += f"å­—æ•°: {word_number / 10000:.2f}ä¸‡å­—\n"
                else:
                    message_text += f"å­—æ•°: æ— \n"
                score = novel_info.get('score', 'æ— ')
                scorer = novel_info.get('scorer', 'æ— ')
                scorer_text = f"{scorer}äººè¯„åˆ†" if scorer and scorer != 'æ— ' else "æ— äººè¯„åˆ†"
                message_text += f"è¯„åˆ†: {score} ({scorer_text})\n"
                message_text += f"çŠ¶æ€: {novel_info.get('status', 'æ— ')}\n"
                message_text += f"æ›´æ–°: {novel_info.get('update_time_str', 'æ— ')}\n"
                synopsis = novel_info.get('synopsis', 'æ— ')
                message_text += f"ç®€ä»‹: {synopsis}\n"
                message_text += f"é“¾æ¥: {novel_info.get('link', novel_url)}\n"
                reviews = novel_info.get('reviews', [])
                if reviews:
                    message_text += "\n--- ğŸ“ æœ€æ–°ä¹¦è¯„ ---\n"
                    for review in reviews:
                        author = review.get('author', 'åŒ¿å')
                        rating = review.get('rating', 'æ— ')
                        content = review.get('content', 'æ— ')
                        message_text += f"{author} ({rating}åˆ†): {content}\n"
                chain = []
                if novel_info.get('image_url'):
                    image_url = novel_info['image_url']
                    try:
                        timeout = aiohttp.ClientTimeout(total=10)
                        async with session.get(image_url, timeout=timeout) as img_response:
                            img_response.raise_for_status()
                            image_bytes = await img_response.read()
                        image_base64 = base64.b64encode(image_bytes).decode()
                        image_component = Comp.Image(file=f"base64://{image_base64}")
                        chain.append(image_component)
                    except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                        logger.warning(f"âŒ ä¸‹è½½å°é¢å›¾ç‰‡å¤±è´¥ (è¶…æ—¶æˆ–é“¾æ¥æ— æ•ˆ): {e}")
                        message_text = "ğŸ–¼ï¸ å°é¢åŠ è½½å¤±è´¥\n\n" + message_text
                chain.append(Comp.Plain(message_text))
                yield event.chain_result(chain)
            else:
                yield event.plain_result(f"ğŸ˜¢ æ— æ³•ä»é¡µé¢ {novel_id} æå–æœ‰æ•ˆä¿¡æ¯ã€‚")
        except aiohttp.ClientResponseError as e:
            logger.error(f"âŒ è®¿é—®è¯¦æƒ…é¡µ {novel_url} å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {e.status}")
            raise e
        except Exception as e:
            logger.error(f"è§£æä¹¦ç±è¯¦æƒ…é¡µå¤±è´¥: {e}", exc_info=True)
            raise e

    @filter.command("ys")
    async def youshu_search_command(self, event: AstrMessageEvent):
        command_text = event.message_str.strip()
        command_parts = command_text.split()
        if not command_parts or command_parts[0].lower() != 'ys' or len(command_parts) < 2:
            yield event.plain_result("âŒ ç”¨æ³•: /ys <ä¹¦å> [åºå· | -é¡µç ]")
            return
        args = command_parts[1:]
        book_name, page_to_list, item_index = "", 1, None
        last_arg = args[-1] if args else ""
        if len(args) > 1 and last_arg.startswith('-') and last_arg[1:].isdigit():
            page_to_list = int(last_arg[1:])
            if page_to_list == 0: page_to_list = 1
            book_name = " ".join(args[:-1]).strip()
        elif len(args) > 1 and last_arg.isdigit():
            item_index = int(last_arg)
            if item_index == 0: item_index = None
            book_name = " ".join(args[:-1]).strip()
        else:
            book_name = " ".join(args).strip()
        if not book_name:
            yield event.plain_result("âŒ è¯·æä¾›æœ‰æ•ˆçš„ä¹¦åè¿›è¡Œæœç´¢ã€‚")
            return
        logger.info(f"ç”¨æˆ· {event.get_sender_id()} è§¦å‘ /ys, æœç´¢:'{book_name}', åºå·:{item_index}, åˆ—è¡¨é¡µ:{page_to_list}")
        try:
            async with aiohttp.ClientSession() as session:
                results_per_page = 20 if self.api == 2 else 15
                page_to_fetch = page_to_list
                if item_index is not None:
                    if item_index == 0:
                        yield event.plain_result("âŒ åºå·å¿…é¡»ä»1å¼€å§‹ã€‚")
                        return
                    page_to_fetch = (item_index - 1) // results_per_page + 1
                search_info = await self._perform_search(session, book_name, page=page_to_fetch)
                if search_info is None or not search_info[0]:
                    yield event.plain_result(f"ğŸ˜¢ æœªæ‰¾åˆ°å…³äºã€{book_name}ã€‘çš„ä»»ä½•ä¹¦ç±ä¿¡æ¯ã€‚")
                    return
                search_results, max_pages = search_info
                if page_to_fetch > max_pages and max_pages > 0:
                    yield event.plain_result(f"âŒ æ‚¨è¯·æ±‚çš„ç¬¬ {page_to_fetch} é¡µä¸å­˜åœ¨ï¼Œã€{book_name}ã€‘çš„æœç´¢ç»“æœæœ€å¤šåªæœ‰ {max_pages} é¡µã€‚")
                    return
                if item_index is None and len(search_results) == 1 and max_pages == 1:
                    selected_book = search_results[0]
                    novel_id = selected_book.get('id')
                    if not novel_id:
                        yield event.plain_result("âŒ æ— æ³•è·å–è¯¥ä¹¦ç±çš„IDã€‚")
                        return
                    async for result in self._get_and_format_novel_details(event, session, str(novel_id)):
                        yield result
                    return
                if item_index is None:
                    start_num = (page_to_fetch - 1) * results_per_page + 1
                    message_text = f"ä»¥ä¸‹æ˜¯ã€{book_name}ã€‘çš„ç¬¬ {page_to_fetch}/{max_pages} é¡µæœç´¢ç»“æœ:\n"
                    for i, book in enumerate(search_results):
                        num = start_num + i
                        name = book.get('novel_name', 'æœªçŸ¥ä¹¦ç±')
                        author = book.get('author_name', 'æœªçŸ¥ä½œè€…')
                        score = book.get('score', 'N/A')
                        scorer = book.get('scorer', '0')
                        message_text += f"{num}. {name}\n    ä½œè€…ï¼š{author} | è¯„åˆ†: {score} ({scorer}äºº)\n"
                    message_text += f"\nğŸ’¡ è¯·ä½¿ç”¨ `/ys {book_name} <åºå·>` æŸ¥çœ‹è¯¦æƒ…"
                    if page_to_fetch < max_pages:
                        message_text += f"ï¼Œæˆ– `/ys {book_name} -{page_to_fetch + 1}` ç¿»é¡µã€‚"
                    yield event.plain_result(message_text)
                else:
                    index_on_page = (item_index - 1) % results_per_page
                    if not (0 <= index_on_page < len(search_results)):
                        yield event.plain_result(f"âŒ åºå·ã€{item_index}ã€‘åœ¨ç¬¬ {page_to_fetch} é¡µä¸Šä¸å­˜åœ¨ã€‚")
                        return
                    selected_book = search_results[index_on_page]
                    novel_id = selected_book.get('id')
                    if not novel_id:
                        yield event.plain_result(f"âŒ æ— æ³•è·å–åºå·ä¸ºã€{item_index}ã€‘çš„ä¹¦ç±IDã€‚")
                        return
                    async for result in self._get_and_format_novel_details(event, session, str(novel_id)):
                        yield result
        except Exception as e:
            logger.error(f"æœç´¢ä¹¦ç± '{book_name}' å¤±è´¥: {e}", exc_info=True)
            yield event.plain_result(f"âŒ æœç´¢ä¹¦ç±æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")

    @filter.command("éšæœºå°è¯´")
    async def youshu_random_command(self, event: AstrMessageEvent):
        max_retries = 10
        async with aiohttp.ClientSession() as session:
            try:
                latest_id = await self._get_latest_novel_id(session)
                if not latest_id:
                    yield event.plain_result("âŒ æŠ±æ­‰ï¼Œæœªèƒ½è·å–åˆ°æœ€æ–°çš„å°è¯´IDï¼Œæ— æ³•è¿›è¡Œéšæœºæœç´¢ã€‚")
                    return
            except Exception as e:
                logger.error(f"è·å–æœ€æ–°IDæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                yield event.plain_result("âŒ è·å–æœ€æ–°å°è¯´IDæ—¶å‡ºé”™ï¼Œè¯·ç¨åå†è¯•ã€‚")
                return
            for attempt in range(max_retries):
                random_id = random.randint(1, latest_id)
                logger.info(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•éšæœºID: {random_id}")
                try:
                    async for result in self._get_and_format_novel_details(event, session, str(random_id)):
                        yield result
                    return
                except aiohttp.ClientResponseError as e:
                    if e.status == 404:
                        logger.warning(f"é¡µé¢ {random_id} ä¸å­˜åœ¨ (404)ï¼Œæ­£åœ¨é‡è¯•...")
                        continue
                    else:
                        logger.error(f"è®¿é—®éšæœºé¡µé¢æ—¶å‘ç”ŸHTTPé”™è¯¯: {e.status}", exc_info=True)
                        yield event.plain_result(f"âŒ è®¿é—®éšæœºé¡µé¢æ—¶å‡ºé”™: HTTP {e.status}")
                        return
                except (ValueError, asyncio.TimeoutError) as e:
                    logger.warning(f"å¤„ç†éšæœºID {random_id} å¤±è´¥: {e}ï¼Œæ­£åœ¨é‡è¯•...")
                    continue
                except Exception as e:
                    logger.error(f"å¤„ç†éšæœºID {random_id} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
                    yield event.plain_result(f"âŒ å¤„ç†éšæœºä¹¦ç±æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚")
                    return
        yield event.plain_result("ğŸ˜¢ æŠ±æ­‰ï¼Œå¤šæ¬¡å°è¯•åä»æœªæ‰¾åˆ°æœ‰æ•ˆçš„å°è¯´é¡µé¢ã€‚è¯·ç¨åå†è¯•ã€‚")

    async def terminate(self):
        """æ’ä»¶é”€æ¯æ—¶çš„æ¸…ç†å·¥ä½œ"""
        logger.info("å°è¯´æœç´¢æ’ä»¶å·²å¸è½½")